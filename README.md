[English](README-en.md)

# LLaVA_OpenVLA

## ç›®çš„

ç ”ç©¶ç”¨æ›´å¼ºçš„MLLMï¼ˆå¦‚LLaVA-OneVisionï¼‰é…ä¸ŠOpenVLAçš„æ•°æ®ä¼šä¸ä¼šç›¸æ¯”RTç³»åˆ—å’ŒOpenVLAæœ‰æ›´å¥½çš„æ•ˆæœï¼ŒåŒæ—¶å¯ä»¥çµæ´»è°ƒæ•´æ•°æ®ç»“æ„ï¼Œå¯ä»¥ç ”ç©¶ä¸åŒæ•°æ®mixå¯¹æ€§èƒ½çš„å½±å“ï¼Œä»¥åŠscaling law

å…¨éƒ¨ä»£ç éƒ½è·‘é€šäº†ï¼Œæ•ˆæœæœªçŸ¥ï¼ˆç”±äºæŸäº›åŸå› æœºå™¨äººæœ¨æœ‰äº† QWQ

å®Œæ•´è¯¦ç»†ç¬”è®°ï¼ˆnotionï¼‰ï¼Œä¸»è¦å†…å®¹åŒ…æ‹¬ï¼š

https://darren-dong.notion.site/OpenVLA-LLaVA-11a471fbaea480839ee6ca55f122a187?pvs=4darren-dong.notion.site/OpenVLA-LLaVA-11a471fbaea480839ee6ca55f122a187?pvs=4

- OpenVLAè®ºæ–‡é‡Œçš„ä¸€äº›æ¶æ„å’Œå®ç°ç»†èŠ‚
- Prismaticåº“ï¼ˆOpenVLAåŸºäºè¿™ä¸ªåº“æ”¹çš„ï¼‰çš„å¤§è‡´ç»“æ„
- OpenVLAç›¸æ¯”Prismaticåº“ä¿®æ”¹äº†å“ªäº›ï¼Œç»†è‡´ç†è§£
- LLaVA-OVåº“ä¿®æ”¹çš„è¯¦ç»†ç»†èŠ‚ï¼š
  - ä¸‹è½½æ•°æ®ï¼ˆæ”¯æŒæŒ‰æ¯”ä¾‹ä¸‹ï¼Œä¸ç”¨å…¨éƒ¨ä¸‹ä¸‹æ¥é€‰ï¼Œå¤ªå¤šäº†ï¼‰
  - è½¬æ¢æ•°æ®ï¼ˆåŸºäºOpenVLAè®­ç»ƒæ”¹çš„ï¼Œé»‘ç›’å¤„ç†ä¿è¯æ— è¯¯ï¼Œå»æ‰äº†å¯¹å›¾ç‰‡resizeçš„æ“ä½œï¼‰
  - ç”¨LLaVAåº“è¿›è¡Œè®­ç»ƒï¼ˆå®ç°äº†action tokenizerï¼Œç”¨æ–°æ•°æ®è®­ç»ƒåå¯ä»¥è¾“å‡ºaction tensorï¼‰

---

## ä»£ç åº“

[Darren-greenhand/LLaVA_OpenVLA: Converted the training data of OpenVLA into general form of multimodal training instructions and then used with LLaVA-OneVision](https://github.com/Darren-greenhand/LLaVA_OpenVLA)

ä¸‹è½½æ•°æ®å¤§æ¦‚æ˜¯450Gï¼Œè½¬æ¢æˆllavaæ ¼å¼å¤§æ¦‚600G

ç¬¬äºŒæ­¥OpenVLAè½¬æ¢æ•°æ®æˆllavaæ ¼å¼ï¼Œå¤§æ¦‚12h

ç¬¬ä¸‰æ­¥è®­ç»ƒï¼Œ8*A100ï¼Œbsæ‹‰æ»¡ï¼Œdeepspeed zero2ï¼Œå¤§çº¦æ˜¯130H



å› ä¸ºå‡ ä¸ªç¯å¢ƒç›¸äº’å†²çªå¤ªéš¾æ”¹äº†ï¼Œå¹²è„†å°±è¿˜æ˜¯ç”¨ä¸‰ä¸ªç¯å¢ƒï¼ˆcondaå¾ˆæ–¹ä¾¿ï¼‰ï¼š

ç¯å¢ƒ1ï¼Œä¸‹è½½æ•°æ®ç”¨ï¼š

[Darren-greenhand/rlds_dataset_part: LLaVA_OpenVLA part 1, supports downloading custom percentage of Open-X data and performing simple processing](https://github.com/Darren-greenhand/rlds_dataset_part)

ç¯å¢ƒ2ï¼Œè½¬æ¢æ•°æ®æˆMLLMæ ‡å‡†æ ¼å¼

[Darren-greenhand/OpenVLA: LLaVA_OpenVLA part 2, Generate MLLM general training data](https://github.com/Darren-greenhand/OpenVLA)

ç¯å¢ƒ3ï¼Œè®­ç»ƒLLaVAæˆstrong VLAæ¨¡å‹

[Darren-greenhand/LLaVA-Next: LLaVA_OpenVLA part 3, Use LLaVA to train a stronger VLA model](https://github.com/Darren-greenhand/LLaVA-Next)

---



## ä½¿ç”¨æ–¹æ³•

rlds_data æ˜¯part1çš„ç¯å¢ƒï¼Œopenvlaæ˜¯part2çš„ç¯å¢ƒï¼Œllavaovæ˜¯part3çš„ç¯å¢ƒ

åŸºæœ¬ç¯å¢ƒé…ç½®éƒ½å’ŒåŸæœ¬çš„åº“æ˜¯ä¸€æ ·çš„ï¼Œæ²¡æœ‰é­”æ”¹ï¼Œéƒ½æ˜¯æ”¹çš„æºä»£ç è€Œéç¯å¢ƒ

ï¼ˆè·¯å¾„å¤ªéš¾æ”¹äº†ï¼Œæˆ‘å°±ç…§æ¬serverä¸Šçš„äº†ï¼‰

ç¬¬ä¸€æ­¥ï¼ˆç¯å¢ƒ1ï¼‰ï¼šä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®ï¼Œè¦ç¿»å¢™

1. æ›´æ”¹`prepare_open_x.sh`çš„æ•°æ®é›†é€‰ç”¨å’Œæ¯”ä¾‹

2. ```shell
   conda activate rlds_data
   cd /data/jcy/project/rlds_dataset_part
   ./prepare_open_x.sh
   # bridgeæ˜¯ç°æˆçš„ï¼Œcopyä¸€éƒ¨åˆ†ï¼Œæ‰§è¡ŒğŸ‘‡
   ./prepare_bridge.sh
   # æ³¨æ„dobbeçš„æ•°æ®é”™ä¹±ï¼Œéœ€è¦ä¿®æ”¹shæ–‡ä»¶ä¸­åˆ¤æ–­train_fileçš„æ¡ä»¶
   # æ³¨æ„ï¼Œå¦‚æœå•ç‹¬æ‰§è¡Œmodify_rlds_dataset.py ä¹Ÿä¸€å®šè¦ç¿»å¢™ï¼ï¼ï¼ä¸ç„¶ä¼šå‡ºæŠ½è±¡bug
   ```

ç¬¬äºŒæ­¥ï¼ˆç¯å¢ƒ2ï¼‰ï¼š

1. ä¿®æ”¹`generate_llavadata.sh` é‡Œçš„ data_mix

2. åœ¨`/data/jcy/project/openvla/prismatic/vla/datasets/rlds/oxe/mixtures.py`æ³¨å†Œä¸€ä¸ªmix

3. ```shell
   conda activate openvla
   cd /data/jcy/project/openvla
   ./generate_llavadata.sh
   # æœªçŸ¥åŸå› æœ€åä¼šå¡ä½ï¼Œä½†å…¶å®å·²ç»ç”Ÿæˆå¥½äº†
   ```

4. python /data/jcy/project/openvla/shuffle_reid_rename.py #å¤„ç†åºå·ï¼Œshuffleï¼Œä»¥åŠæ”¹æˆllavaç›¸å¯¹è·¯å¾„æ ¼å¼ï¼Œrenameæ˜¯ç›´æ¥é‡å‘½åä¸ä¿ç•™ï¼Œcpæ˜¯å¤‡ä»½ï¼ˆdebugç”¨ï¼‰



ç¬¬ä¸‰æ­¥ï¼ˆç¯å¢ƒ3ï¼‰ï¼š

1. ä¿®æ”¹`/data/jcy/project/LLaVA-NeXT/scripts/train/vla.yaml` çš„json_pathï¼Œimage_dirï¼ˆä¸Šä¸€æ­¥ç”Ÿæˆçš„ï¼‰

2. ```shell
   conda activate llavaov
   cd /data/jcy/project/LLaVA-NeXT
   ./scripts/train/finetune_ov_vla.sh
   ```

OKï¼Œå°±è®­ç»ƒå¥½äº†



ä½¿ç”¨å°±åœ¨part3 llavaåº“é‡Œï¼Œ `python inference_action.py`







LLaVAæ˜¯å¤šæ¨¡æ€å¼€æºé¡¹ç›®é‡Œåšçš„å¾ˆå¥½çš„åº“ï¼ˆå› ä¸ºä¼šå¼€æºæ•°æ®ï¼Œè™½ç„¶1.6æ‹–äº†å¾ˆä¹…ï¼‰ï¼Œæ—©æœŸä»£ç ç»“æ„æ¯”è¾ƒé€šä¿—æ˜“æ‡‚ï¼ˆåé¢æ›´æ–°ä»¥åæœ‰å¾ˆå¤šå†—ä½™ï¼ŒåŸºæœ¬å¾ˆéš¾è°ƒç”¨çš„ä»£ç ï¼Œçœ‹çš„å¤´ç–¼ï¼ˆ

OpenVLAæ˜¯ä¸€ä¸ªå®ç°VLAçš„å¾ˆå¥½çš„å·¥ä½œï¼Œä½†æ˜¯é‡Œé¢ç”¨çš„æ¨¡å‹æ¯”è¾ƒè€æ—§ï¼Œå¦‚æœæ›´æ–°æ¨¡å‹ï¼Œæ€§èƒ½å¯èƒ½ä¼šæœ‰è¾ƒå¤§çš„æå‡ã€‚

é»˜è®¤çš„MIXï¼š

| Registered Dataset Name                               | # Episodes | ratio | File Size (GB) |
| ----------------------------------------------------- | ---------- | ----- | -------------- |
| fractal20220817_data                                  | 73,499     | 0.15  | 111.06         |
| kuka                                                  | 580,392    | 0.07  | 778.02         |
| bridge                                                | 25,460     | 0.2   | 387.49         |
| taco_play                                             | 3,242      | 0.2   | 47.77          |
| jaco_play                                             | 976        | 0.3   | 9.24           |
| berkeley_cable_routing                                | 1,482      | 0.3   | 4.67           |
| roboturk                                              | 2,144      | 0.2   | 45.39          |
| viola                                                 | 135        | 0.5   | 10.4           |
| berkeley_autolab_ur5                                  | 896        | 0.3   | 76.39          |
| toto                                                  | 901        | 0.3   | 127.66         |
| language_table                                        | 442,226    | 0.1   | 399.22         |
| stanford_hydra_dataset_converted_externally_to_rlds   | 550        | 0.4   | 72.48          |
| austin_buds_dataset_converted_externally_to_rlds      | 50         | 0.5   | 1.49           |
| nyu_franka_play_dataset_converted_externally_to_rlds  | 456        | 0.3   | 5.18           |
| furniture_bench_dataset_converted_externally_to_rlds  | 5100       | 0.15  | 110            |
| ucsd_kitchen_dataset_converted_externally_to_rlds     | 150        | 0.5   | 1.33           |
| austin_sailor_dataset_converted_externally_to_rlds    | 250        | 0.5   | 18.85          |
| austin_sirius_dataset_converted_externally_to_rlds    | 600        | 0.4   | 6.55           |
| bc_z                                                  | 39,350     | 0.2   | 80.54          |
| dlr_edan_shared_control_converted_externally_to_rlds  | 100        | 0.5   | 3.09           |
| iamlab_cmu_pickup_insert_converted_externally_to_rlds | 520        | 0.4   | 50.29          |
| utaustin_mutex                                        | 1,500      | 0.2   | 20.79          |
| berkeley_fanuc_manipulation                           | 415        | 0.4   | 8.85           |
| cmu_stretch                                           | 135        | 0.5   | 0.71           |
| dobbe                                                 | 5208       | 0.1   | 21.1           |
| fmb                                                   | 1804       | 0.2   | 356.5          |

ç°åœ¨ï¼š113,178æ¡è½¨è¿¹  450G



è‡´è°¢ï¼š

[moojink/rlds_dataset_mod: Efficiently apply modification functions to RLDS/TFDS datasets.](https://github.com/moojink/rlds_dataset_mod/tree/main)

[openvla/openvla: OpenVLA: An open-source vision-language-action model for robotic manipulation.](https://github.com/openvla/openvla)

[LLaVA-VL/LLaVA-NeXT](https://github.com/LLaVA-VL/LLaVA-NeXT/)
